---
layout: default
title: "AnÃ¡lisis de Flujo de Datos Simulado con Spark"
---

# ğŸ”¥ AnÃ¡lisis de Flujo de Datos Simulado con Spark

> ğŸ’¡ **Objetivo:**  
> Aplicar analÃ­tica avanzada con **Apache Spark** para procesar un flujo de clics simulado en una tienda online de lectura digital.  
> El propÃ³sito es comprender cÃ³mo los usuarios navegan e interactÃºan con la plataforma en tiempo real.

---

## âœ… 1. Escenario

Imagina una **pÃ¡gina de lectura de libros en lÃ­nea** que desea analizar el comportamiento de sus lectores.  
Cada clic representa una acciÃ³n del usuario: abrir un libro, pasar de capÃ­tulo, marcar una pÃ¡gina o cerrar sesiÃ³n.

La tienda necesita detectar patrones de navegaciÃ³n para:

- ğŸ‘¥ Identificar usuarios activos  
- ğŸš€ Encontrar picos de interacciÃ³n  
- âš ï¸ Detectar comportamientos sospechosos  
- ğŸ¯ Evaluar la eficiencia de campaÃ±as en tiempo real  

---

## ğŸ“Š 2. Dataset

![Tabla Ejemplo del DataSet]({{ '/assets/images/Dataset_Clicks.png' | relative_url }})

**Columnas principales:**

| Columna | DescripciÃ³n |
|----------|--------------|
| `Timestamp` | Fecha y hora del clic |
| `User_ID` | Identificador del usuario |
| `Clicks` | NÃºmero de clics por evento |

ğŸ“ˆ **TamaÃ±o del dataset:** 100 registros simulados (10 usuarios distintos).  

---

## âš™ï¸ 3. Proceso en Spark

El anÃ¡lisis se ejecutÃ³ en **Google Colab** con PySpark.  
Pasos del procesamiento:

1. Cargar el archivo CSV.  
2. Convertir la columna `Timestamp` a tipo fecha.  
3. Simular un flujo de datos en micro-lotes de 1 minuto.  
4. Contar los clics por usuario dentro de cada ventana temporal.  

Ejemplo de cÃ³digo:

```python
from pyspark.sql import SparkSession
from pyspark.sql.functions import sum as _sum

spark = SparkSession.builder.appName("Clickstream Analysis").getOrCreate()
df = spark.read.csv("clickstream_books.csv", header=True, inferSchema=True)
clicks_per_user = df.groupBy("User_ID").agg(_sum("Clicks").alias("Total_Clicks"))
clicks_per_user.show()

ğŸ“ˆ 4. Resultados del AnÃ¡lisis

Patrones observados:

ğŸ§­ Algunos usuarios realizan muchos clics en intervalos cortos â†’ lectores muy activos.

âš¡ Picos repentinos de clics â†’ oportunidades para promociones o eventos.

â±ï¸ La distribuciÃ³n temporal revela los horarios de mayor actividad.

ğŸ§© 5. Â¿CÃ³mo ayuda esto a la tienda?

Los resultados permiten:

ğŸ¯ Mejor segmentaciÃ³n de usuarios segÃºn su actividad.

ğŸ¤– DetecciÃ³n de bots o comportamientos automatizados.

ğŸ§  OptimizaciÃ³n de recomendaciones de lectura.

ğŸ’° Toma de decisiones en tiempo real para campaÃ±as de marketing.

ğŸ—ï¸ 6. Arquitectura del Blog con Jekyll

Motor: Jekyll
Tema: Cayman

Estructura del proyecto:

/_posts/                  # Publicaciones Markdown
/_layouts/                # Plantillas HTML
/assets/images/           # GrÃ¡ficos y visuales
_config.yml               # ConfiguraciÃ³n global
index.md                  # PÃ¡gina principal


Despliegue en GitHub Pages:

Instalar Ruby y Jekyll.

Crear blog: jekyll new mi-blog.

Editar _config.yml â†’ theme: jekyll-theme-cayman.

Subir el proyecto a GitHub.

Activar GitHub Pages.

Agregar este post en _posts/2025-11-04-analisis-flujo-datos-spark.md.

![GrÃ¡fico de clics por usuario]({{ '/assets/images/clicks.png' | relative_url }})

ğŸ’­ 7. ReflexiÃ³n Final
ğŸ”„ Â¿Streaming o Batch?
Procesamiento por Lotes (Batch)	Procesamiento en Streaming
Procesa grandes volÃºmenes completos	Procesa datos en tiempo real
Mayor latencia	Baja latencia
Ideal para informes	Ideal para monitoreo
Ejemplo: ventas diarias	Ejemplo: clics en vivo

ğŸš€ En 2025, la analÃ­tica en streaming es esencial para las empresas digitales.
Permite adaptarse rÃ¡pidamente a las necesidades y hÃ¡bitos de los usuarios.

<footer style="text-align:center; font-size:0.9em; color:#777;"> Hecho con â¤ï¸ usando Jekyll + Spark | Proyecto de <strong>Alessandro DÃ­az M.</strong> </footer> ```
